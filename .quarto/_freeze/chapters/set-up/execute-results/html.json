{
  "hash": "3eb72dbbefca9943ffc41e9b2a515137",
  "result": {
    "engine": "knitr",
    "markdown": "# Set-up and data preparation {.unnumbered}\n\nWe begin by uploading packages and writing functions that we will reuse. By convention, whenever we sample distributions, we will use 100,000 draws. We set the randomization seed to 123 for replicability.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'ggplot2' was built under R version 4.3.2\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(truncnorm)\nlibrary(extraDistr)\nlibrary(EnvStats)\nlibrary(janitor)\nlibrary(kde1d)\nlibrary(kableExtra)\n\nset.seed(123)\nn<-100000\n```\n:::\n\n\nWe create a function to sample from the beta distribution, which we use for all prevalence estimates. To sample from the beta distribution we need to be able to find a good standard deviation, based on our estimated ranges and mean. We also write a function to perform a binary search to find a standard deviation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# sample from the beta distribution by specifying the mean proportion an its standard deviation\nsample_beta <- function(mean_val, sd_val) {\n  n <- 100000\n  # calculate alpha and beta parameters\n  var_val <- sd_val^2\n  alpha <- ((1 - mean_val) / var_val - 1 / mean_val) * mean_val^2\n  beta <- alpha * (1 / mean_val - 1)\n  # Check and adjust alpha and beta to ensure they are valid for the beta distribution\n  if (alpha <= 0 | beta <= 0) {\n    stop(\"Invalid shape parameters: alpha and beta must be greater than 0.\")\n  }\n  # sample from beta distribution\n  return(rbeta(n, alpha, beta))\n}\n\n# find a good standard deviation for beta distributions for which we have mean and range estimates by using binary search\nfind_good_sd_binary <- function(mean_val,\n                               fifth_percentile, ninety_fifth_percentile,\n                               tol=0.001, sd_val=-1) {\n  # Set start value\n  if (sd_val == -1){\n    sd_val=0.2\n  }\n  # Check if the provided parameters are valid\n  if (sd_val^2 >= mean_val * (1 - mean_val)) {\n    stop(\"Invalid sd_val: sd_val^2 must be less than mean_val * (1 - mean_val).\")\n  }\n\n  # Initialize the search range\n  lower_bound <- 0\n  upper_bound <- sqrt(mean_val * (1 - mean_val))\n\n  # Perform binary search to find the optimal sd_val\n  while (abs(upper_bound - lower_bound) > tol) {\n    sd_val <- (lower_bound + upper_bound) / 2\n    samples <- sample_beta(mean_val, sd_val)\n    prop_between_given_percentiles <- sum(\n      samples > fifth_percentile & samples < ninety_fifth_percentile) / length(samples)\n\n    if (abs(prop_between_given_percentiles - 0.9) < tol) {\n      return(sd_val)\n    } else if (prop_between_given_percentiles < 0.9) {\n      upper_bound <- sd_val\n    } else {\n      lower_bound <- sd_val\n    }\n  }\n  return((lower_bound + upper_bound) / 2)\n}\n```\n:::\n\n\nNext, we write functions to sample from the dirichlet distribution and the truncated log-normal distribution, which we use for estimating pain intensity and some durations of pain, respectively.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# sample from Dirichlet distribution\nsample_dirichlet<-function(a=0, b=0, x=0, y=0){\n  if (sum(c(a, b, x, y)) != 100){\n    print(\"Arguments do not sum to 100! Their sum is: \")\n    print(sum(c(a, b, x, y)))\n  } else {\n    n <- 100000\n    non_zero_args = c(a, b, x, y)[c(a, b, x, y) != 0]\n    return(rdirichlet(n, non_zero_args))\n  }\n}\n\n# sample from truncated log-normal distribution\nsample_trunclogn <- function(n_value, mean, sd, min_value, max_value){\n  trunclogn_dist<-rlnormTrunc(n = n_value, meanlog = log(mean^2 / sqrt(mean^2 + sd^2)),\n                    sdlog = sqrt(log(1 + (sd^2/mean^2))),\n                    min=min_value, max=max_value)\n  return(trunclogn_dist)\n}\n```\n:::\n\n\nFinally, we make a function to print tables of our results:\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_table=function(x){\nkable(x, table.attr = 'data-quarto-disable-processing=\"true\"') %>%\n    kableExtra::kable_styling(full_width=FALSE, position=\"center\", font_size=12,\n                  bootstrap_options = c(\"condensed\")) \n}\n```\n:::\n\n\n# Prevalence\n\nThere are four broad categories of shrimp farms: extensive, semi-intensive, intensive, and super-intensive.\n\nBased on 2018 data from [Boyd et al. (2021)](https://doi.org/10.1111/jwas.12841), and accounting for increasing intensification, we estimate the percentage of penaeid shrimp raised in different production systems as:\n\n-   Extensive: \\~11.2%\n-   Semi-intensive: \\~16.4%\n-   Intensive: \\~71.4%\n-   Super-intensive: \\~1%\n\nAlthough we assume these estimates are credible, we add in a modest amount of uncertainty to account for potential weaknesses in [Boyd et al. (2018)](https://doi.org/10.1111/jwas.12841), changes that may have occurred since the survey was conducted, and because these proportions relate to the shrimp produced at the end of production---they do not account for individuals who die pre-slaughter.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define the expected proportions for each practice\next_mean <- 0.112\nsemi_mean <- 0.164\nint_mean <- 0.714\nsuper_mean <- 0.01\n\nsum(c(ext_mean,semi_mean,int_mean,super_mean))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1\n```\n\n\n:::\n\n```{.r .cell-code}\n# Sample from the Dirichlet distribution\nprop_sample<-data.frame(sample_dirichlet(ext_mean*100, semi_mean*100, \n                                         int_mean*100, super_mean*100))\n# we multiply by 100 to make the distributions less noisy\ncolnames(prop_sample)<-c(\"Ext\", \"Semi\", \"Int\", \"Super\")\n\nproduction_summarydist<-round(rbind((quantile(x =prop_sample[,1], probs = c(.05, .50, .95))), \n       (quantile(x =prop_sample[,2], probs = c(.05, .50, .95))), \n        (quantile(x =prop_sample[,3], probs = c(.05, .50, .95))),\n        (quantile(x =prop_sample[,4], probs = c(.05, .50, .95)))), 2)\nrow.names(production_summarydist)<-c(\"Extensive\",\"Semi-Intensive\",\"Intensive\", \"Super-Intensive\")\nproduction_summarydist \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  5%  50%  95%\nExtensive       0.07 0.11 0.17\nSemi-Intensive  0.11 0.16 0.23\nIntensive       0.64 0.72 0.79\nSuper-Intensive 0.00 0.01 0.03\n```\n\n\n:::\n:::\n\n\nWe then estimate prevalence ranges and means, based on data where possible, and draw from the beta distribution. Where no data on the mean is available, we often set the mean to be the mid point of the estimated range. Where no data on the range is available we use the rough, subjective likelihood categories below:\n\n-   Very unlikely: 10%\n-   Unlikely: 25%\n-   Unsure how likely: 50%\n-   Likely: 75%\n-   Very likely: 90%\n\n# Duration (pre-slaughter mortality)\n\nFor time, we always use hours as the unit. We base pain duration on the scientific literature where possible.\n\nThe average time spent in pain from any given welfare threat has to account for shrimp that die prematurely from that or other welfare threats, because this reduces how long shrimp can suffer from that threat in the aggregate.\n\nIf a threat is a one-off event in a shrimp's life (e.g., slaughter), we just model estimated duration. Otherwise, if it occurs regularly, we often model duration as the pain caused to a shrimp *per day*, and then weight by an estimate of the average number of days lived by a shrimp (including those that die pre-slaughter). We can then also estimate the proportion of shrimp experiencing welfare threats that are life-stage specific (e.g., slaughter).\n\nWe use the estimates presented in [Waldhorn and Autric's (2023)](http://doi.org/10.31219/osf.io/b8n3t) [Guesstimate model](https://www.getguesstimate.com/models/21262). Specifically, we use the mortality rate of each life stage multiplied by the mean number of days a shrimp lives given that they die in a certain life stage, and then weight these by the proportion of farmed shrimp each species accounts for.\n\n::: {.callout-note collapse=\"true\" icon=\"true\"}\n**Note:** the guesstimate model re-samples each time it is opened so the figures you see may differ slightly from those used here.\n:::\n\nTo best sample from the Guesstimate data (especially the tails of the distributions) and to remove errors created by Guesstimate (e.g., negative values), we generated 100,000 synthetic samples for each of these, based off the original 5000 guesstimate samples. To do this, we use the `kde1d` function, which estimates a kernel density function from the 5000 samples, and the `rkde1d` function, which generates n (in our case 100,000) samples from the estimated kernel density.\n\n## Number of shrimp dying on farms {#sec-shrimpnumbers}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# loading die on farms samples, taken from Guesstimate model\n\nallspecies_dof_samp<-read.csv(\"../data/die_on_farm_samples.csv\", header=TRUE, sep=\",\")\n\nvannamei_dof<-allspecies_dof_samp$vannamei[allspecies_dof_samp$vannamei>0] %>% # Cell GZ in the Guesstimate model\n  # removing negative values created by Guesstimate\n  kde1d(xmin=0) %>% # running kde1d function and ensuring no values below 0 are created\n  rkde1d(100000,.) # creating 100,000 samples from the data\n\n# repeat this for other taxa\nmonodon_dof<-allspecies_dof_samp$monodon[allspecies_dof_samp$monodon>0] %>% # Cell ES in the Guesstimate model\n  kde1d(xmin=0) %>%\n  rkde1d(100000,.)\n\notherpen_dof<-allspecies_dof_samp$other_pen[allspecies_dof_samp$other_pen>0] %>% # Cell NN in the Guesstimate model\n  kde1d(xmin=0) %>%\n  rkde1d(100000,.)\n```\n:::\n\n\nNow we can calculate the proportion of farmed shrimp accounted for by each species for each of our 100,000 samples.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nallspecies_dof<-cbind(vannamei_dof, monodon_dof, otherpen_dof) # combining the 100,000 samples for each species into a data frame\n\nprop_allspecies<-as.data.frame(allspecies_dof) %>% \n  rowwise() %>%\n  mutate(van_prop=vannamei_dof/sum(vannamei_dof, monodon_dof, otherpen_dof), # calculating each sample as a proportion of the total shrimp, row-wise\n         mon_prop=monodon_dof/sum(vannamei_dof, monodon_dof, otherpen_dof),\n         otherpen_prop=otherpen_dof/sum(vannamei_dof, monodon_dof, otherpen_dof))\n\nprop_allspecies_dof<-as.data.frame(prop_allspecies[,4:6]) # keeping only the proportions\n\nsaveRDS(allspecies_dof, file=\"../data/allspecies_dof.RData\")\nsaveRDS(prop_allspecies_dof, file=\"../data/prop_allspecies_dof.RData\")\n```\n:::\n\n\n## Days lived by life stage\n\nNext we load the data for the number of days lived by a shrimp, given that it dies within a certain life stage. The three life stages under consideration here are postlarval, juvenile-adult, and the days lived before slaughter, which we call the total farmed days.\n\n\n::: {.cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\n# First load the data\nvannamei_days_samp<-read.csv(\"../data/vannamei_days_lived.csv\", header=TRUE,sep=\",\") # Cells TE, VO, XM, and QV in the Guesstimate model\nmonodon_days_samp<-read.csv(\"../data/monodon_days_lived.csv\", header=TRUE, sep=\",\") # Cells MF, HI, OZ, and LW in the Guesstimate model\notherpen_days_samp<-read.csv(\"../data/otherpen_days_lived.csv\", header=TRUE, sep=\",\") # Cells NQ, XV, DQ, and YY in the Guesstimate model\n\n# Next make the 100,000 samples\n\n# create empty data frame\nvannamei_days_lived<-data.frame(postlarval=rep(NA, 100000),\n                                juvenile.adult=rep(NA, 100000),\n                                total.farmed=rep(NA, 100000))\n\n# fill empty data frame with data simulated from Guesstimate data using kde1d function\nvannamei_days_lived$postlarval<-vannamei_days_samp$postlarval %>% \n  kde1d() %>%\n  rkde1d(100000,.)\nvannamei_days_lived$juvenile.adult<-vannamei_days_samp$juvenile.adult %>% \n  kde1d() %>%\n  rkde1d(100000,.)\n\n# repeat for other species\nmonodon_days_lived<-data.frame(postlarval=rep(NA, 100000),\n                               juvenile.adult=rep(NA, 100000),\n                               total.farmed=rep(NA, 100000))\n\nmonodon_days_lived$postlarval<-monodon_days_samp$postlarval %>% \n  kde1d() %>%\n  rkde1d(100000,.)\nmonodon_days_lived$juvenile.adult<-monodon_days_samp$juvenile.adult[monodon_days_samp$juvenile.adult<214] %>% \n  kde1d(xmax=213.99) %>% # guesstimate produced some large samples over what we think is the maximum ongrowing length (see below) so we restrict to one day prior to the maximum ongrowing period (as this is the maximum age a juvenile--adult can be while still dying pre-slaughter)\n  rkde1d(100000,.)\n\notherpen_days_lived<-data.frame(postlarval=rep(NA, 100000),\n                             juvenile.adult=rep(NA, 100000),\n                             total.farmed=rep(NA, 100000))\n\notherpen_days_lived$postlarval<-otherpen_days_samp$postlarval %>% \n  kde1d() %>%\n  rkde1d(100000,.)\notherpen_days_lived$juvenile.adult<-otherpen_days_samp$juvenile.adult[otherpen_days_samp$juvenile.adult<153] %>% \n  kde1d(xmax=152.99) %>% # guesstimate produced some large samples over what we think is the maximum ongrowing length (see below) so we restrict to just prior to the maximum ongrowing period (as this is the maximum age a juvenile--adult can be while still dying pre-slaughter)\n  rkde1d(100000,.)\n```\n:::\n\n\nGuesstimate produced a few large numbers of over one year for the total days farmed, which seems incorrect, so we remove these and restrict to:\n\n-   183 days for *P. vannamei* ([FAO (2009a)](https://perma.cc/DT32-95S6) suggests the maximum cycle is 6 months in ongrowing 6 months = \\~183 days)\n-   214 days for *P. monodon* ([FAO (2009b)](https://perma.cc/72G5-H63W) suggests the maximum cycle is \\>6 months in ongrowing, so we assume \\~7 months, which = \\~214 days)\n-   153 days for other penaeids (Table 4.6c--d in [Wickens and Lee (2002)](https://doi.org/10.1002/9780470995082.ch4) suggests the maximum cycle is 4 months of ongrowing. As other penaeids can refer to many different species, we are more uncertain about this value, so we increase the maximum to 5 months. 5 months = \\~153 days)\n\nThe `kde1d` function will still produce a few samples just above this estimation.\n\n\n::: {.cell layout-ncol=\"3\"}\n\n```{.r .cell-code}\nvannamei_days_lived_total<-vannamei_days_samp$total_farmed_d[vannamei_days_samp$total_farmed_d<183]\nvannamei_days_lived$total.farmed<-vannamei_days_lived_total %>% \n  kde1d() %>% \n  rkde1d(100000,.)\n\nmonodon_days_lived_total<-monodon_days_samp$total_farmed_d[monodon_days_samp$total_farmed_d<214]\nmonodon_days_lived$total.farmed<-monodon_days_lived_total %>% \n  kde1d() %>%\n  rkde1d(100000,.)\n\notherpen_days_lived_total<-otherpen_days_samp$total_farmed_d[otherpen_days_samp$total_farmed_d<153]\notherpen_days_lived$total.farmed<-otherpen_days_lived_total %>% \n  kde1d() %>%\n  rkde1d(100000,.)\n```\n:::\n\n\n## Mortality rates by life stage\n\nNow we load the data for the mortality rates samples, then make the 100,000 samples.\n\n\n::: {.cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\nvannamei_mort_samp<-read.csv(\"../data/vannamei_mortality_rates.csv\",header=TRUE, sep=\",\") # Cells UY, UJ, and TF in the Guesstimate model\nmonodon_mort_samp<-read.csv(\"../data/monodon_mortality_rates.csv\", header=TRUE, sep=\",\") # Cells ZA, XZ, and YR in the Guesstimate model\notherpen_mort_samp<-read.csv(\"../data/otherpen_mortality_rates.csv\", header=TRUE,sep=\",\")\n # Cells MU, UQ, and XJ in the Guesstimate model\n\nvannamei_stage_prob<-data.frame(postlarval=rep(NA, 100000),\n                                juvenile.adult=rep(NA, 100000))\n\n# fill empty data frame with data simulated from Guesstimate data using kde1d function\nvannamei_stage_prob$postlarval<-vannamei_mort_samp$postlarval %>% \n  kde1d(xmin = 0,\n        xmax = 1) %>%\n  rkde1d(100000,.)\nvannamei_stage_prob$juvenile.adult<-vannamei_mort_samp$juvenile.adult[vannamei_mort_samp$juvenile.adult<1] %>% \n  kde1d(xmin = 0, # The juvenile-adult samples from Guesstimate sampled some instances over 1 so we get rid of these first, or else the xmin and xmax functions won't work\n        xmax = 1) %>%\n  rkde1d(100000,.)\n\n# repeat for other taxa\nmonodon_stage_prob<-data.frame(postlarval=rep(NA, 100000),\n                               juvenile.adult=rep(NA, 100000))\n\nmonodon_stage_prob$postlarval<-monodon_mort_samp$postlarval %>% \n  kde1d(xmin = 0,\n        xmax = 1) %>%\n  rkde1d(100000,.)\nmonodon_stage_prob$juvenile.adult<-monodon_mort_samp$juvenile.adult %>% \n  kde1d(xmin = 0,\n        xmax = 1) %>%\n  rkde1d(100000,.)\n\notherpen_stage_prob<-data.frame(postlarval=rep(NA, 100000),\n                             juvenile.adult=rep(NA, 100000))\n\notherpen_stage_prob$postlarval<-otherpen_mort_samp$postlarval %>% \n  kde1d(xmin = 0,\n        xmax = 1) %>%\n  rkde1d(100000,.)\notherpen_stage_prob$juvenile.adult<-otherpen_mort_samp$juvenile.adult %>% \n  kde1d(xmin = 0,\n        xmax = 1) %>%\n  rkde1d(100000,.)\n```\n:::\n\n\nRight now we have the probability that a shrimp dies in each stage, conditional on the shrimp having survived previous stages. However, we want the cumulative probability of a shrimp dying in the ongrowing period---for example, the probability of dying in the juvenile--adult stage is\n\n$1-p(dying\\ in\\ postlarval\\ stage)*p(dying\\ in\\ juvenile--adult\\ stage)$.\n\nWe also calculate the probability of a shrimp surviving to slaughter age, which means it has survived both postlarval and juvenile--adult stages.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create new columns with the total probability they make it to each stage \nvannamei_stage_prob_total<-vannamei_stage_prob %>% \n  rowwise() %>%\n  mutate(postlarval.total=postlarval,\n         juvenile.adult.total=(1-postlarval)*juvenile.adult,\n         slaughter.age.total=(1-postlarval)*(1-juvenile.adult))\nvannamei_stage_prob_total<-as.data.frame(vannamei_stage_prob_total) %>%\n  select(ends_with(\"total\")) # keep only the totals\n\n# repeat for other species\nmonodon_stage_prob_total<-monodon_stage_prob %>% \n  rowwise() %>%\n  mutate(postlarval.total=postlarval,\n         juvenile.adult.total=(1-postlarval)*juvenile.adult,\n         slaughter.age.total=(1-postlarval)*(1-juvenile.adult))\nmonodon_stage_prob_total<-as.data.frame(monodon_stage_prob_total)%>%\n  select(ends_with(\"total\"))\n\notherpen_stage_prob_total<-otherpen_stage_prob %>% \n  rowwise() %>%\n  mutate(postlarval.total=postlarval,\n         juvenile.adult.total=(1-postlarval)*juvenile.adult,\n         slaughter.age.total=(1-postlarval)*(1-juvenile.adult))\notherpen_stage_prob_total<-as.data.frame(otherpen_stage_prob_total) %>%\n  select(ends_with(\"total\"))\n```\n:::\n\n\n## Calculating pre-slaughter mortality rates {#sec-preslaughtmort}\n\nNow we can calculate the pre-slaughter mortality rate across the production cycle. This will give us estimates of the average number of days lived by a shrimp.\n\nTo get a weighted average mortality rate we need to weight the life stage rates by the probability a shrimp is from a given species. We start by creating vector of species chosen according to probabilities from proportions calculated above (see @sec-shrimpnumbers).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspecies_chosen = vapply(\n  1:100000,\n  function(i) {sample.int(3, size=1, prob=prop_allspecies_dof[i, ])},\n  integer(1))\n\n# Check that the proportions look correct\nprint(data.frame(vannamei.prop=length(species_chosen[species_chosen==1])/length(species_chosen),\n                 monodon.prop=length(species_chosen[species_chosen==2])/length(species_chosen),\n                 otherpen.prop=length(species_chosen[species_chosen==3])/length(species_chosen)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  vannamei.prop monodon.prop otherpen.prop\n1       0.82507       0.0832       0.09173\n```\n\n\n:::\n:::\n\n\nNow, we make a data frame of 100,000 stage probabilities, weighted by the proportion of farmed shrimp that comes from each species.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstage_probabilities = matrix(NA, nrow=100000, ncol=3)\nfor (i in 1:100000){\n  if (species_chosen[i] == 1){\n    stage_probabilities[i, ] = as.matrix(vannamei_stage_prob_total[i,])\n  }\n  if (species_chosen[i] == 2){\n    stage_probabilities[i, ] = as.matrix(monodon_stage_prob_total[i,])\n  }\n  if (species_chosen[i] == 3){\n    stage_probabilities[i, ] = as.matrix(otherpen_stage_prob_total[i,])\n  }\n}\nhead(stage_probabilities)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          [,1]       [,2]      [,3]\n[1,] 0.2279207 0.02892378 0.7431556\n[2,] 0.1233640 0.05429026 0.8223458\n[3,] 0.1248379 0.21950486 0.6556573\n[4,] 0.1639346 0.12880184 0.7072636\n[5,] 0.1902008 0.08136774 0.7284314\n[6,] 0.1596227 0.11999293 0.7203843\n```\n\n\n:::\n\n```{.r .cell-code}\nsaveRDS(stage_probabilities, file=\"../data/stage_probabilities.RData\")\n```\n:::\n\n\nNow we can calculate the weighted days lived for each life stage of each species.\n\n\n::: {.cell}\n\n```{.r .cell-code}\naverage_days_lived = rep(NA, 100000)\n\nfor (i in 1:100000){\n  stage_chosen <- sample.int(3, size=1, prob=stage_probabilities[i, ])\n  # P. vannamei\n  if (species_chosen[i] == 1){\n    if (stage_chosen == 1){\n      average_days_lived[i] = vannamei_days_lived$postlarval[i] \n    }\n    if (stage_chosen == 2){\n      average_days_lived[i] = vannamei_days_lived$juvenile.adult[i] \n    }\n    if (stage_chosen == 3){\n      average_days_lived[i] = vannamei_days_lived$total.farmed[i] \n    }\n  }\n  # P. monodon\n  if (species_chosen[i] == 2){\n    if (stage_chosen == 1){\n      average_days_lived[i] = monodon_days_lived$postlarval[i]\n    }\n    if (stage_chosen == 2){\n      average_days_lived[i] = monodon_days_lived$juvenile.adult[i]\n    }\n    if (stage_chosen == 3){\n      average_days_lived[i] = monodon_days_lived$total.farmed[i]\n    }\n  }\n  # other penaeids\n  if (species_chosen[i] == 3){\n    if (stage_chosen == 1){\n      average_days_lived[i] = otherpen_days_lived$postlarval[i]\n    }\n    if (stage_chosen == 2){\n      average_days_lived[i] = otherpen_days_lived$juvenile.adult[i]\n    }\n    if (stage_chosen == 3){\n      average_days_lived[i] = otherpen_days_lived$total.farmed[i]\n    }\n  }\n}\n\nhead(average_days_lived)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  92.828757 140.129031  85.592464 122.142815 111.202064   9.701857\n```\n\n\n:::\n\n```{.r .cell-code}\nquantile(average_days_lived, probs = c(0.01, .05, .50, .95))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       1%        5%       50%       95% \n 11.46242  13.92991 133.03242 175.05771 \n```\n\n\n:::\n\n```{.r .cell-code}\nmean(average_days_lived)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 114.8756\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(density(average_days_lived), main= \"Average mortality rate of farmed penaeid shrimp\", xlab=\"Days\")\n```\n\n::: {.cell-output-display}\n![](set-up_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n\n```{.r .cell-code}\nsaveRDS(average_days_lived, file=\"../data/average_days_lived.RData\")\n```\n:::\n\n\n# Intensity\n\nWe use the Pain-Track framework ([Alonso & Schuck-Paim, 2021a](https://doi.org/10.1186/s13104-021-05636-2)) developed by [Welfare Footprint](https://welfarefootprint.org/) to compare the overall burden of different welfare threats affecting farmed shrimp. The pain categories are: annoying, hurtful, disabling, and excruciating, with each worse than the last.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npaincategories<-c(\"Excruciating\", \"Disabling\", \"Hurtful\", \"Annoying\")\n```\n:::\n\n\nWelfare Footprint's pain track categories are based on functional differences between qualitatively different types of pain. Thus, they are, strictly speaking, ordinal, not cardinal representations of pain severity.\n\nHowever, leaving the pain categories disaggregated does not allow for an overall comparison of welfare threats because, for instance, some threats may have a long duration exclusively in mild pain categories, while others may have briefer threats in more severe categories. Here, we use Disabling as the reference category and assign weights to the other severity categories that are relative to it. We draw from uniform distributions for the pain category weightings as we have high uncertainty about how much worse or better different pain categories are, or whether long-lasting, mild pains should be prioritized over shorter, more severe pains or vice versa. In particular, we are uncertain about whether excruciating pain is a few or many orders of magnitude worse than disabling pain. For more discussion of this issue, see [McAuliffe and Shriver (2023)](https://perma.cc/H24Y-7G2E).\n\nOur lower bounds for excruciating pain and upper bounds for annoying and disabling pain are weights favored by [Duffy (2023, p.18)](https://docs.google.com/document/d/1p7xqop2FlIF8Kw45za0NnJPwvUA70Mb1UzjijMRKRr8/edit#bookmark=id.lyp2mcdwi2sh) and [Šimčikas (2022)](https://perma.cc/8DJP-XWCA). The weights were therefore as follows:\n\n-   Annoying: 0.002 to 0.01\n-   Hurtful: 0.02 to 0.2\n-   Disabling: 1\n-   Excruciating: 5 to 1000\n\nYou can change the input below if you disagree with the relative weights. Moreover, all of the inputs below can be changed to reflect your personal beliefs about the intensity, duration, and prevalence of each welfare harm.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nAnnoying_Weight<-runif(n = 100000, min = (1/500), max = (1/100))\nHurtful_Weight<-runif(n = 100000, min = (1/50), max = (1/5))\nDisabling_Weight <- 1\nExcruciating_Weight<-runif(n = 100000, min = 5, max = 1000)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](set-up_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "set-up_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}